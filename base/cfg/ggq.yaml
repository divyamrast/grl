type: experiment/online_learning
rate: 0
environment:
  type: environment/modeled
  model:
    type: model/dynamical
    dynamics:
      type: dynamics/pendulum
    control_step: 0.03
  task:
    type: task/pendulum/swingup
agent:
  type: agent/td
  policy:
    type: policy/discrete/random
    discretizer:
      type: discretizer/uniform
      min: environment/task/action_min
      max: environment/task/action_max
      steps: [3]
  predictor:
    type: predictor/ggq
    alpha: 0.2
    eta: 0.01
    gamma: 0.97
    lambda: 0.65
    projector:
      type: projector/tilecoding
      tilings: 16
      resolution: [ 0.31415, 3.1415, 3 ]
      wrapping: [ 6.283, 0, 0 ]
      memory: 8
    theta:
      type: representation/parameterized/linear
      memory: agent/predictor/projector/memory
    w:
      type: representation/parameterized/linear
      memory: agent/predictor/projector/memory
      max: 0
    policy:
      type: policy/discrete/q
      representation: agent/predictor/theta
      discretizer: agent/policy/discretizer
      sampler:
        type: sampler/greedy
visualization:
  type: visualization/value_function
  visualizer:
    type: visualizer/glut
  projector: agent/predictor/projector
  representation: agent/predictor/theta
  policy:
    type: policy/discrete/q
    discretizer: agent/policy/discretizer
    sampler:
      type: sampler/greedy
  min: environment/task/observation_min
  max: environment/task/observation_max
  points: 65536
 