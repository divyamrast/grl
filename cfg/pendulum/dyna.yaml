experiment:
  type: experiment/online_learning
  rate: 0
  test_interval: 1
  runs: 20
  steps: 2000
  output: dyna
  environment: include/pendulum_swingup.yaml
  agent:
    type: agent/dyna
    planning_steps: 2000
    predictor:
      type: predictor/sarsa
      alpha: 0.2
      gamma: 0.97
      lambda: 0.65
      projector: include/tile_coding.yaml
      representation:
        type: representation/parameterized/linear
        memory: experiment/agent/predictor/projector/memory
      trace:
        type: trace/enumerated/replacing
    policy: include/q_exploration_policy.yaml
    model:
      type: observation_model/fixed_reward
      wrapping: [ 6.283, 0 ]
      observation_min: experiment/environment/task/observation_min
      observation_max: experiment/environment/task/observation_max
      projector: include/ann_model_projector.yaml
      representation:
        type: representation/llr
        outputs: 4
        projector: experiment/agent/model/projector
      task: experiment/environment/task
    model_predictor:
      type: predictor/model
      wrapping: experiment/agent/model/wrapping
      projector: experiment/agent/model/projector
      representation: experiment/agent/model/representation
    model_agent:
      type: agent/td
      predictor:
        type: predictor/sarsa
        alpha: 0.02
        gamma: experiment/agent/predictor/gamma
        lambda: experiment/agent/predictor/lambda
        projector: experiment/agent/predictor/projector
        representation: experiment/agent/predictor/representation
        trace:
          type: trace/enumerated/replacing
      policy: experiment/agent/policy
  test_agent:
    type: agent/fixed
    policy: include/q_greedy_policy.yaml
visualizer:
  type: visualizer/glut
visualization: include/viz_value_function.yaml
visualization: include/viz_pendulum.yaml
