experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 0
  steps: 0
  rate: 0
  test_interval: 10
  environment: 
    type: environment/sandbox
    model: 
      type: sandbox_model/dynamical
      control_step: 0.03
      integration_steps: 25
      dynamics: 
        type: dynamics/rbdl_leo
        file: leo_fb_sl.lua
        points: tip_left, heel_left, root
        auxiliary: mm, com, comv, am
      dof_count: 4
      action_min: [-10.7, -10.7, -10.7]
      action_max: [10.7,  10.7,  10.7]
    task: 
      type: task/leoSquatFA
      timeout: 5
      initial_setpoint: 0.368641
      rand_init: 1
  agent: 
    type: agent/black_box
    episodes: 10
    optimizer: 
      type: optimizer/cma
      population: 0
      sigma: [1]
      policy: 
        type: policy/parameterized/pid
        setpoint: [0.389273, -0.881163, 0.656759, 0, 0, 0]
        outputs: experiment/environment/task/action_dims
        p: [25, 0, 0, 0, 25, 0, 0, 0, 25, 2, 0, 0, 0, 2, 0, 0, 0, 1]
        i: []
        d: []
        il: []
  test_agent: 
    type: agent/fixed
    policy: experiment/agent/optimizer/policy
  save_every: never
