agent/black_box:
  description: Agent that learns from the cumulative reward of complete rollouts
  episodes:
    type: int
    description: Number of episodes to evaluate policy
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  optimizer:
    type: optimizer
    description: Policy optimizer
    mutability: configuration
    default: 0
    optional: 0
agent/fixed:
  description: Fixed-policy agent
  policy:
    type: policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
agent/master/exclusive:
  description: Master agent that selects one sub-agent to execute
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent1:
    type: agent/sub
    description: First subagent
    mutability: configuration
    default: 0
    optional: 0
  agent2:
    type: agent/sub
    description: Second subagent
    mutability: configuration
    default: 0
    optional: 0
agent/master/predicated:
  description: Master agent in which execution is predicated on preceding agent confidence
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  control_step:
    type: double.control_step
    description: Characteristic step time on which gamma is defined
    mutability: system
    default: 0.05
    optional: 1
    min: 0
    max: 1
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent1:
    type: agent/sub
    description: First subagent
    mutability: configuration
    default: 0
    optional: 0
  agent2:
    type: agent/sub
    description: Second subagent
    mutability: configuration
    default: 0
    optional: 0
agent/master/sequential:
  description: Master agent that executes sub-agents sequentially
  agent1:
    type: agent
    description: First subagent, providing the suggested action
    mutability: configuration
    default: 0
    optional: 0
  agent2:
    type: agent
    description: Second subagent, providing the final action
    mutability: configuration
    default: 0
    optional: 0
agent/solver:
  description: Agent that successively solves learned models of the environment
  interval:
    type: int
    description: Episodes between successive solutions (0=asynchronous)
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  policy:
    type: policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  solver:
    type: solver
    description: Model-based solver
    mutability: configuration
    default: 0
    optional: 0
agent/sub/compartmentalized:
  description: Sub agent that is valid in a fixed state-space region
  min:
    type: vector.observation_min
    description: Minimum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Maximum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  agent:
    type: agent
    description: Sub agent
    mutability: configuration
    default: 0
    optional: 0
agent/sub/voluntary:
  description: Sub agent that has confidence as part of the action
  dim:
    type: int
    description: Action dimension that indicates confidence
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  agent:
    type: agent
    description: Sub agent
    mutability: configuration
    default: 0
    optional: 0
agent/td:
  description: Agent that learns from observed state transitions
  policy:
    type: policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
communicator/zeromq:
  description: A zeromq class capable to establish a link by events and send messages asynchronously (publisher/subscriber)
  pub:
    type: string
    description: Publisher address
    mutability: configuration
    default: tcp://*:5561
    optional: 1
  sub:
    type: string
    description: subscriber address
    mutability: configuration
    default: tcp://192.168.1.10:5562
    optional: 1
  event:
    type: string
    description: Event address
    mutability: configuration
    default: ""
    optional: 1
  event_mode:
    type: string
    description: Event mode
    mutability: configuration
    default: ""
    optional: 1
discretizer/peaked:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/uniform:
  description: Uniform discretizer
  min:
    type: vector
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
dynamics/cart_pole:
  description: Cart-pole dynamics from Barto et al.
dynamics/pendulum:
  description: Pendulum dynamics based on the DCSC MOPS
dynamics/rbdl:
  description: RBDL rigid body dynamics
  file:
    type: string
    description: RBDL Lua model file
    mutability: configuration
    default: ""
    optional: 1
  options:
    type: string
    description: Lua string to execute when loading model
    mutability: configuration
    default: ""
    optional: 1
environment/communicator:
  description: Communicator environment which interects with a real environment by sending and receiving messages
  communicator:
    type: communicator
    description: Comunicator which exchanges messages with an actual environment
    mutability: configuration
    default: 0x726f746163696e75
    optional: 0
environment/leo_squat:
  description: Leo squatting environment
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ""
    optional: 1
  target_env:
    type: environment
    description: Interaction environment
    mutability: configuration
    default: 0
    optional: 0
  observe:
    type: string
    description: string.observe
    mutability: configuration
    default: Comma-separated list of state elements observed by an agent
    optional: 1
  actuate:
    type: string
    description: string.actuate
    mutability: configuration
    default: Comma-separated list of action elements provided by an agent
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  observation_min:
    type: vector.observation_min
    description: Lower limit of observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit of observations
    mutability: system
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit of action
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit of action
    mutability: system
    default: "[  ]"
    optional: 1
environment/leo_walk:
  description: Leo walking environment
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ""
    optional: 1
  target_env:
    type: environment
    description: Interaction environment
    mutability: configuration
    default: 0
    optional: 0
  observe:
    type: string
    description: string.observe
    mutability: configuration
    default: Comma-separated list of state elements observed by an agent
    optional: 1
  actuate:
    type: string
    description: string.actuate
    mutability: configuration
    default: Comma-separated list of action elements provided by an agent
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  observation_min:
    type: vector.observation_min
    description: Lower limit of observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit of observations
    mutability: system
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit of action
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit of action
    mutability: system
    default: "[  ]"
    optional: 1
  learn_stance_knee:
    type: int
    description: Learn stance knee
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
environment/modeled:
  description: Environment that uses a state transition model internally
  model:
    type: model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: state
    description: Current state of the model
    mutability: provided
environment/ode:
  description: Open Dynamics Engine simulation environment
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ../addons/odesim/cfg/robot.xml
    optional: 1
  randomize:
    type: int
    description: Randomize initial state
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  visualize:
    type: int
    description: Whether to display 3D visualization
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
environment/sandbox:
  description: Non-Markov environment
  model:
    type: sandbox_model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: state
    description: Current state of the model
    mutability: provided
experiment/batch_learning:
  description: Batch learning experiment using randomly sampled experience
  runs:
    type: int
    description: Number of separate learning runs to perform
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  batches:
    type: int
    description: Number of batches per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  batch_size:
    type: int
    description: Number of transitions per batch
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  rate:
    type: int
    description: Test trial control step frequency in Hz
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  output:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  model:
    type: model
    description: Model in which the task is set
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to be solved
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Learner
    mutability: configuration
    default: 0
    optional: 0
  test_agent:
    type: agent
    description: Agent to use in test trials after each batch
    mutability: configuration
    default: 0
    optional: 0
  observation_min:
    type: vector.observation_min
    description: Lower limit for observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit for observations
    mutability: system
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit for actions
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit for actions
    mutability: system
    default: "[  ]"
    optional: 1
  state:
    type: state
    description: Current observed state of the environment
    mutability: provided
experiment/online_learning:
  description: Interactive learning experiment
  runs:
    type: int
    description: Number of separate learning runs to perform
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  trials:
    type: int
    description: Number of episodes per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  steps:
    type: int
    description: Number of steps per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  rate:
    type: int
    description: Control step frequency in Hz
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  test_interval:
    type: int
    description: Number of episodes in between test trials
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 2147483647
  output:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  environment:
    type: environment
    description: Environment in which the agent acts
    mutability: configuration
    default: 0
    optional: 0
  agent:
    type: agent
    description: Agent
    mutability: configuration
    default: 0
    optional: 0
  test_agent:
    type: agent
    description: Agent to use in test trials
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: state
    description: Current observed state of the environment
    mutability: provided
  curve:
    type: state
    description: Learning curve
    mutability: provided
  load_file:
    type: string
    description: Load policy filename
    mutability: configuration
    default: ""
    optional: 1
  save_every:
    type: string
    description: Save policy to 'output' at the end of event
    mutability: configuration
    default: never
    optional: 1
    options:
      - never
      - run
      - test
      - trail
exporter/csv:
  description: Comma-separated values exporter
  file:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  fields:
    type: string
    description: Comma-separated list of fields to write
    mutability: configuration
    default: ""
    optional: 1
  style:
    type: string
    description: Header style
    mutability: configuration
    default: line
    optional: 1
    options:
      - none
      - line
      - meshup
  variant:
    type: string
    description: Variant of exporter
    mutability: configuration
    default: test
    optional: 1
    options:
      - test
      - learn
      - all
  split_runs:
    type: int
    description: Write each run output to a separate file
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
importer/csv:
  description: Comma-separated values importer
  file:
    type: string
    description: Input base filename
    mutability: configuration
    default: ""
    optional: 1
model/compass_walker:
  description: Simplest walker model from Garcia et al.
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: configuration
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  integrator_out:
    type: string
    description: string.integrator_out_
    mutability: configuration
    default: ""
    optional: 1
model/dynamical:
  description: State transition model that integrates equations of motion
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  dynamics:
    type: dynamics
    description: Equations of motion
    mutability: configuration
    default: 0
    optional: 0
observation_model/approximated:
  description: Observation model based on observed transitions
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  control_step:
    type: double.control_step
    description: Control step time (0 = estimate using SMDP approximator)
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  stddev_limit:
    type: double
    description: Maximum standard deviation of acceptable predictions, as fraction of range
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
observation_model/fixed:
  description: Observation model based on known state transition model
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  model:
    type: model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
observation_model/fixed_reward:
  description: Observation model based on observed transitions but known task
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  control_step:
    type: double.control_step
    description: Control step time (0 = estimate using SMDP approximator)
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  stddev_limit:
    type: double
    description: Maximum standard deviation of acceptable predictions, as fraction of range
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment
    mutability: configuration
    default: 0
    optional: 0
optimizer/cma:
  description: Coverance matrix adaptation black-box optimizer
  population:
    type: int
    description: Population size
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  sigma:
    type: vector
    description: Initial standard deviation (a single-element vector will be replicated for all parameters)
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  policy:
    type: policy/parameterized
    description: Control policy prototype
    mutability: configuration
    default: 0
    optional: 0
policy/action:
  description: Policy based on a direct action representation
  sigma:
    type: vector
    description: Standard deviation of exploration distribution
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
policy/action_probability:
  description: Policy based on an action-probability representation
  discretizer:
    type: discretizer
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Action-probability representation
    mutability: configuration
    default: 0
    optional: 0
policy/discrete/q:
  description: Q-value based policy
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from action-values
    mutability: configuration
    default: 0
    optional: 0
policy/discrete/q/bounded:
  description: Q-value based policy with bounded action deltas
  bound:
    type: vector
    description: Maximum action delta
    mutability: configuration
    default: "[  ]"
    optional: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from action-values
    mutability: configuration
    default: 0
    optional: 0
policy/discrete/random:
  description: Policy that chooses discrete random actions
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
policy/discrete/v:
  description: State-value based policy
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  model:
    type: observation_model
    description: Observation model
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from state-values
    mutability: configuration
    default: 0
    optional: 0
policy/feed_forward:
  description: Feed-forward policy
  input:
    type: string
    description: string.input_
    mutability: configuration
    default: CSV file with timestep and controls
    optional: 1
policy/mhe_nmpc:
  description: Nonlinear model predictive control policy with moving horizon estimator using the MUSCOD library
  lua_model:
    type: string
    description: Lua model used by MUSCOD
    mutability: configuration
    default: ""
    optional: 1
  model_name:
    type: string
    description: Name of the model in grl
    mutability: configuration
    default: ""
    optional: 1
  mhe_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  nmpc_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  verbose:
    type: int
    description: Verbose mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
policy/mhe_nmpc_sw:
  description: Nonlinear model predictive control policy for the simplest walker with moving horizon estimator using the MUSCOD library
  model_name:
    type: string
    description: Name of the model in grl
    mutability: configuration
    default: ""
    optional: 1
  mhe_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  nmpc_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  verbose:
    type: int
    description: Verbose mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
policy/nmpc:
  description: Nonlinear model predictive control policy using the MUSCOD library
  lua_model:
    type: string
    description: Lua model used by MUSCOD
    mutability: configuration
    default: ""
    optional: 1
  model_name:
    type: string
    description: Name of the model in grl
    mutability: configuration
    default: ""
    optional: 1
  nmpc_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  verbose:
    type: int
    description: Verbose mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
policy/nmpc_sw:
  description: Nonlinear model predictive control policy for the simplest walker using the MUSCOD library
  model_name:
    type: string
    description: Name of the model in grl
    mutability: configuration
    default: ""
    optional: 1
  nmpc_model_name:
    type: string
    description: Name of MUSCOD MHE model library
    mutability: configuration
    default: ""
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  verbose:
    type: int
    description: Verbose mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
policy/nmpc_th:
  description: Nonlinear multistep (thread-based) model predictive control policy using the MUSCOD library
  model_name:
    type: string
    description: Name of MUSCOD model library
    mutability: configuration
    default: ""
    optional: 1
  lua_model:
    type: string
    description: Lua model used by MUSCOD
    mutability: configuration
    default: ""
    optional: 1
  inputs:
    type: int.observation_dims
    description: Number of inputs
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  single_step:
    type: int
    description: Run NMPC in single-step mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
  verbose:
    type: int
    description: Verbose mode
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
policy/parameterized/action:
  description: Parameterized policy based on a direct action representation
  sigma:
    type: vector
    description: Standard deviation of exploration distribution
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation/parameterized.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
policy/parameterized/pid:
  description: Parameterized policy based on a proportional-integral-derivative controller
  setpoint:
    type: vector
    description: Setpoint
    mutability: online
    default: "[  ]"
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  p:
    type: vector
    description: P gains ([in1_out1, ..., in1_outN, ..., inN_out1, ..., inN_outN])
    mutability: online
    default: "[  ]"
    optional: 1
  i:
    type: vector
    description: I gains
    mutability: online
    default: "[  ]"
    optional: 1
  d:
    type: vector
    description: D gains (use P gain on velocity instead, if available)
    mutability: online
    default: "[  ]"
    optional: 1
  il:
    type: vector
    description: Integration limits
    mutability: online
    default: "[  ]"
    optional: 1
policy/parameterized/pidt:
  description: Parameterized policy based on a proportional-integral-derivative controller for tranjectory tracking
  policy:
    type: policy
    description: Control policy
    mutability: configuration
    default: 0x70203a656c626172
    optional: 0
  inputs:
    type: int.observation_dims
    description: Number of inputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  p:
    type: vector
    description: P gains ([in1_out1, ..., in1_outN, ..., inN_out1, ..., inN_outN])
    mutability: online
    default: "[  ]"
    optional: 1
  i:
    type: vector
    description: I gains
    mutability: online
    default: "[  ]"
    optional: 1
  d:
    type: vector
    description: D gains (use P gain on velocity instead, if available)
    mutability: online
    default: "[  ]"
    optional: 1
  il:
    type: vector
    description: Integration limits
    mutability: online
    default: "[  ]"
    optional: 1
policy/random:
  description: Policy that chooses continuous random actions
  output_min:
    type: vector.action_min
    description: Lower action limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper action limit
    mutability: system
    default: "[  ]"
    optional: 1
predictor/ac/action:
  description: Actor-critic predictor for direct action policies
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: Actor learning rate
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  critic_projector:
    type: projector.observation
    description: Projects observations onto critic representation space
    mutability: configuration
    default: 0
    optional: 0
  critic_representation:
    type: representation.value/state
    description: Value function representation
    mutability: configuration
    default: 0
    optional: 0
  critic_trace:
    type: trace
    description: Trace of critic projections
    mutability: configuration
    default: 0
    optional: 0
  actor_projector:
    type: projector.observation
    description: Projects observations onto actor representation space
    mutability: configuration
    default: 0
    optional: 0
  actor_representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
  actor_trace:
    type: trace
    description: Trace of actor projections
    mutability: configuration
    default: 0
    optional: 1
predictor/ac/probability:
  description: Actor-critic predictor for action-probability policies
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: Actor learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  critic_projector:
    type: projector.observation
    description: Projects observations onto critic representation space
    mutability: configuration
    default: 0
    optional: 0
  critic_representation:
    type: representation.value/state
    description: Value function representation
    mutability: configuration
    default: 0
    optional: 0
  critic_trace:
    type: trace
    description: Trace of critic projections
    mutability: configuration
    default: 0
    optional: 0
  actor_projector:
    type: projector.pair
    description: Projects observation-action pairs onto actor representation space
    mutability: configuration
    default: 0
    optional: 0
  actor_representation:
    type: representation.value/action
    description: Action-probability representation
    mutability: configuration
    default: 0
    optional: 0
  actor_trace:
    type: trace
    description: Trace of actor projections
    mutability: configuration
    default: 0
    optional: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
predictor/advantage:
  description: Advantage learning off-policy value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  kappa:
    type: double
    description: Advantage scaling factor
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: A-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
predictor/expected_sarsa:
  description: Expected SARSA low-variance on-policy value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: policy/discrete/q
    description: Q-value based policy
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Target distribution
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
predictor/full/qi:
  description: Deterministic model-based action-value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/full/vi:
  description: Deterministic model-based state-value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State-value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/model:
  description: Observation model predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
predictor/qv:
  description: QV on-policy value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: State-action value learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: State value learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  q_projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  q_representation:
    type: representation.value/action
    description: State-action value representation (Q)
    mutability: configuration
    default: 0
    optional: 0
  v_projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  v_representation:
    type: representation.value/state
    description: State value representation (V)
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
predictor/sarsa:
  description: SARSA on-policy value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
predictor/shaped_sarsa:
  description: SARSA predictor with shaping rewards
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
  shaping_representation:
    type: representation.value/action
    description: Q-value representation for shaping rewards
    mutability: configuration
    default: 0
    optional: 0
predictor/td:
  description: TD value function predictor
  importer:
    type: importer
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 0
projector/pre/normalizing:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/sample/ann:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/tile_coding:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/llr:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann:
  description: Parameterized artificial neural network representation
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  hiddens:
    type: int
    description: Number of hidden nodes
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 64
  steepness:
    type: double
    description: Steepness of activation function
    mutability: configuration
    default: 5
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  bias:
    type: int
    description: Use bias nodes
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  recurrent:
    type: int
    description: Feed hidden activation back as input
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
representation/parameterized/linear:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
sampler/epsilon_greedy:
  description: Maximum search with a uniform random chance of non-maximums
  epsilon:
    type: double
    description: Exploration rate
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1
sampler/greedy:
  description: Maximum search
sampler/softmax:
  description: Softmax (Gibbs/Boltzmann) sampler
  tau:
    type: double
    description: Temperature of Boltzmann distribution
    mutability: online
    default: 1
    optional: 1
    min: 0.001
    max: 100
sandbox_model/compass_walker:
  description: Simplest walker model from Garcia et al. with a sequential evaluation
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: configuration
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  use_avg_velocity:
    type: int
    description: "Velocity type "
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
solver/agent:
  description: Solver that uses a simulated agent
  steps:
    type: int
    description: Number of planning steps before solution is returned
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  horizon:
    type: int
    description: Planning episode length
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  start:
    type: vector
    description: Starting state for planning
    mutability: configuration
    default: "[  ]"
    optional: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  agent:
    type: agent
    description: Agent used for planning episodes
    mutability: configuration
    default: 0
    optional: 0
  state:
    type: state
    description: Current observed state of planning
    mutability: provided
solver/vi:
  description: Value iteration solver
  sweeps:
    type: int
    description: Number of planning sweeps before solution is returned
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  parallel:
    type: int
    description: Perform backups in parallel (requires reentrant representation)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.observation
    description: State space discretizer
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor/full
    description: Predictor to iterate
    mutability: configuration
    default: 0
    optional: 0
task/cart_pole/balancing:
  description: Cart-pole balancing task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_pole/regulator:
  description: Cart-pole regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0, 0, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.1, 0.1, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_pole/swingup:
  description: Cart-pole swing-up task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  randomization:
    type: int
    description: Start state randomization
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 1
  shaping:
    type: int
    description: Whether to use reward shaping
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate for reward shaping
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  end_stop_penalty:
    type: int
    description: Terminate episode with penalty when end stop is reached
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
task/compass_walker/vref:
  description: Compass walker tracking velocity task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after wiich task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  reference_velocity:
    type: double
    description: Reference velocity
    mutability: configuration
    default: 0.12
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  per_step_reward:
    type: int
    description: If set, give reward per every step
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/compass_walker/vrefu:
  description: Compass walker tracking velocity task with controls minimization
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after wiich task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  reference_velocity:
    type: double
    description: Reference velocity
    mutability: configuration
    default: 0.12
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  per_step_reward:
    type: int
    description: If set, give reward per every step
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/compass_walker/walk:
  description: Compass walker walking task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after wiich task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
task/lua:
  description: User-provided task specification in LUA
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  file:
    type: string
    description: Lua task file
    mutability: configuration
    default: ""
    optional: 1
  options:
    type: string
    description: Lua string to execute when loading task
    mutability: configuration
    default: ""
    optional: 1
task/pendulum/regulator:
  description: Pendulum regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 3.14159, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.1, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
task/pendulum/swingup:
  description: Pendulum swing-up task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 2.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  randomization:
    type: double
    description: Level of start state randomization
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
trace/enumerated/accumulating:
  description: Accumulating eligibility trace using a queue of projections
trace/enumerated/replacing:
  description: Replacing eligibility trace using a queue of projections
visualization/cart_pole:
  description: Cart-pole visualization
  state:
    type: state
    description: Cart-pole state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/compass_walker:
  description: Compass walker visualization
  state:
    type: state
    description: Compass walker state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/field/policy/action:
  description: Visualizes a policy over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: state
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  policy:
    type: policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  output_dim:
    type: int
    description: Action dimension to visualize
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
visualization/field/policy/value:
  description: Visualizes the value of a policy over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: state
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: policy/discrete/q
    description: Q-value based control policy
    mutability: configuration
    default: 0
    optional: 0
visualization/field/value:
  description: Visualizes an approximation over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: state
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector
    description: Projects inputs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Value representation
    mutability: configuration
    default: 0
    optional: 0
visualization/pendulum:
  description: Pendulum visualization
  state:
    type: state
    description: Pendulum state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/sample:
  description: Visualizes a sample-based approximation
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: configuration
    default: "[ 0, 1 ]"
    optional: 1
  field_min:
    type: vector
    description: Lower visualization dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  field_max:
    type: vector
    description: Upper visualization dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  points:
    type: int
    description: Texture size
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector/sample
    description: Sample projector whose store to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/sample/random:
  description: Visualizes an approximation over randomly sampled states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: configuration
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  points:
    type: int
    description: Texture size
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector
    description: Projects inputs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Value representation
    mutability: configuration
    default: 0
    optional: 0
visualization/state:
  description: Plots state values
  input_dims:
    type: vector
    description: Input dimensions to visualize
    mutability: online
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  memory:
    type: int
    description: Number of data points to draw
    mutability: online
    default: 256
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: state
    description: State to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/trajectory:
  description: Plots trajectories
  input_dims:
    type: vector
    description: Input dimensions to visualize
    mutability: online
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  trajectory:
    type: trajectory
    description: Trajectory to visualize
    mutability: configuration
    default: 0
    optional: 0
visualizer/glut:
  description: Visualizer based on the GLUT library
projector/pre/normalizing.pair:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked.pair:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling.pair:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/sample/ann.pair:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree.pair:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/tile_coding.pair:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/llr.transition:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int.observation_dims+2
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.pair
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.transition:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  hiddens:
    type: int
    description: Number of hidden nodes
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 64
  steepness:
    type: double
    description: Steepness of activation function
    mutability: configuration
    default: 5
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  bias:
    type: int
    description: Use bias nodes
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  recurrent:
    type: int
    description: Feed hidden activation back as input
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
representation/parameterized/linear.transition:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int.observation_dims+2
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
projector/pre/normalizing.observation:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked.observation:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling.observation:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/sample/ann.observation:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree.observation:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/tile_coding.observation:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/llr.action:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector.action_min
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.observation
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.action:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 64
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  hiddens:
    type: int
    description: Number of hidden nodes
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 64
  steepness:
    type: double
    description: Steepness of activation function
    mutability: configuration
    default: 5
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  bias:
    type: int
    description: Use bias nodes
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  recurrent:
    type: int
    description: Feed hidden activation back as input
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
representation/parameterized/linear.action:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector.action_min
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
discretizer/peaked.action:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector.action_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.action_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/uniform.action:
  description: Uniform discretizer
  min:
    type: vector.action_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.action_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/llr.value/action:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.pair
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.value/action:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  hiddens:
    type: int
    description: Number of hidden nodes
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 64
  steepness:
    type: double
    description: Steepness of activation function
    mutability: configuration
    default: 5
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  bias:
    type: int
    description: Use bias nodes
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  recurrent:
    type: int
    description: Feed hidden activation back as input
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
representation/parameterized/linear.value/action:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/llr.value/state:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.observation
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.value/state:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 0
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  hiddens:
    type: int
    description: Number of hidden nodes
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 64
  steepness:
    type: double
    description: Steepness of activation function
    mutability: configuration
    default: 5
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  bias:
    type: int
    description: Use bias nodes
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  recurrent:
    type: int
    description: Feed hidden activation back as input
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
representation/parameterized/linear.value/state:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
discretizer/peaked.observation:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector.observation_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/uniform.observation:
  description: Uniform discretizer
  min:
    type: vector.observation_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1